

# **自下而上 vs 自上而下**

bottom-up vs top-down

自上而下和自下而上算法是两种常见的问题解决方法，它们在问题求解的方式和思考角度上有所不同。

## top-down

自上而下算法(Top-down approach)是一种**从总体到细节**的求解思路。它首先关注整体的问题，在解决**整体问题时逐步细化为子问题**，直到达到最小的可解决单元。这种方法通常使用**递归或分治**策略来实现。在每个递归步骤中，问题被分解成更小的子问题，然后通过解决这些子问题来逐步构建出整体的解决方案。经典的例子是分治算法和递归算法。

## bottom-up

自下而上算法(Bottom-up approach)则是一种**从细节到总体**的求解思路。它首先**解决最小的子问题**，然后逐步将子问题的解合并为更大规模的问题，直到得到整体的解决方案。这种方法通常使用**迭代或动态规划**来实现。在迭代的每一步中，通过利用已知的子问题解决方案，逐步构建出更大规模问题的解决方案。

总结起来，自上而下算法从总体到细节，通过递归或分治策略来解决问题；而自下而上算法从细节到总体，通过迭代或动态规划来解决问题。选择哪种方法取决于具体问题的性质和求解需求。

# NMS（non-maximum suppression）

非极大值抑制（Non-maximum suppression，NMS）是一种去除非极大值的算法，常用于[计算机视觉](https://so.csdn.net/so/search?q=计算机视觉&spm=1001.2101.3001.7020)中的边缘检测、物体识别等。**作用：！针对多目标问题，能保证对于每个目标留下置信度最高的锚框。**

算法流程：

给出一张图片和上面许多物体检测的候选框（即每个框可能都代表某种物体），但是这些框很可能有互相重叠的部分，我们要做的就是只保留最优的框。假设有N个框，每个框被[分类器](https://so.csdn.net/so/search?q=分类器&spm=1001.2101.3001.7020)计算得到的分数为Si, 1<=i<=N。

0、建造一个存放待处理候选框的集合H，初始化为包含全部N个框；

建造一个存放最优框的集合M，初始化为空集。

1、将所有集合 H 中的框进行排序，选出分数最高的框 m，从集合 H 移到集合 M；

2、遍历集合 H 中的框，分别与框 m 计算交并比（Interection-over-union，IoU），如果高于某个阈值（一般为0~0.5），则认为此框与 m 重叠，将此框从集合 H 中去除。

3、回到第1步进行迭代，直到集合 H 为空。集合 M 中的框为我们所需。

需要优化的参数：

IoU 的阈值是一个可优化的参数，一般范围为0~0.5，可以使用交叉验证来选择最优的参

# **heatmap & coordinate （regression）**

转载：https://zhuanlan.zhihu.com/p/374842773

## 方案一：全连接直接回归坐标

拓展阅读：《How much position information do convolutional neural networks encode?》
关于CNN如何学习到绝对位置坐标？
人体姿态估计一般通过检测方式学习到绝对位置（锚），关键点学习相对位置（很接近3d的smpl套壳）

FC（full connection）坐标回归方案

- 优点：训练和前向速度可以做到很快，端到端全微分训练
- 缺点：缺乏空间泛化能力

***空间泛化能力****是指模型training期间****获取一个位置****的能力，在inference阶段迁移学习到定位另一个位置的能力*



### **训练阶段，FC层权重严重依赖于输入的空间分布**

考虑一种极端情况，即训练集完全由位于图像左半边内的坐标组成。许多完全连接层的输入激活将是无用的，因此与图像右侧对应的权重将不会得到正确、充分的训练。

该问题在小规模数据集上表现得会更为明显

因此，采用全连接输出坐标点方式是会极大损害空间泛化能力:

示例2进一步说明：在训练阶段有一个网球一直在图片左上角，reshape拉成一维向量后，全连接层的激活权重全部在上半部分，而下半部分的权重是没有得到训练的，当你测试时候输入一张球放在了右下角图片，拉成一维向量后，由于下半部分权重失效，理论上是预测不出来的，即没有空间泛化能力。而卷积操作由于权重共享，是可以有效避免的。CNN 相对来说，由于空间共享参数的存在，本身就存在较高的泛化能力。

### **Regression的本质到底是什么？**

实战中发现fc更倾向于预测一个合理的模板，heatmap方法相对关注局部一点得特征，相对来说，heatmap方法更容易出现点位错乱的情况，而fc更多的是单个点精度不足导致偏差
regression模型很容易训练，甚至即是很少的数据也能够训练。当然与此带来的就是极度的**容易过拟合和泛化问题**（如果说数据能够觉得那当我没说）。key points之间的能够保持某种潜在的“秩序”（比如face alignment中双眼+鼻子+两嘴角构成的5个点，这5个点总是会保持方位上的秩序）。这种秩序性更体现在，如果输入是一张完全不相关的图像，regression依然可以给出一个形状上非常合理的结果（反观heatmap所给的key points则会完全乱了套）

总结一下：**全连接方式所得权重严重依赖于训练数据的分布，非常容易造成过拟合**

## 方案二：高斯热图

Heatmap-based方法监督模型学习的是高斯概率分布图，即把GroundTruth中每个点渲染成一张高斯热图，最后网络输出为K张特征图对应K个关键点，然后通过argmax或soft-argmax来获取最大值点作为估计结果。这种方法由于需要渲染高斯热图，且由于热图中的最值点直接对应了结果，不可避免地需要维持一个相对高分辨率的热图（常见的是64x64，再小的话误差下界过大会造成严重的精度损失），因此也就自然而然导致了很大的计算量和内存开销。



heatmap方法一般相对精度更高；但从图像输入到坐标距离并不是一个端到端可微的模型，从heatmap到坐标点，是通过argmax方式离线得到的，该过程并不可导

heatmap一般取输入尺寸1/4大小，输出尺寸大，内存消耗大，且需要后处理，速度相应也会慢

argmax操作同时会带来量化误差，这与heatmap的分辨率有关

文章采用differentiable spatial to numerical transform（DSNT）方法，该方法来源于soft-argmax思路

![img](https://cdn.nlark.com/yuque/0/2024/webp/46293974/1722950856459-00caec13-a183-4f0c-8c4d-4aa051cb7f53.webp)



那么构造heatmap实际上是构造了一个中间状态，这个heatmap有如下的一些优点：

1. 可以让网络全卷积，因为输出就是2维图像，不需要全连接。
2. 关节点之间是有很强的相关关系的。然而直接对每个坐标点数值回归，并不能有效捕捉利用这些相关关系；而一张输入图像对应的heatmap就存在这种相关关系，那就可以用来指导网络进行学习。简言之，头关节的回归可以帮助胸口关节，脖子关节的回归也可以帮助左右肩膀，反之亦然。
3. heatmap同样捕捉了前景（关节点）与背景的对比关系，同样可以用来指导网络进行学习。这样，通过这条途径获得一个比较好的   predictedHeatmap（易于学习，效果很好），再通过其他方法获得最终的关节点位置坐标，就是目前single person pose estimation的基本pipeline。

方式（1）相比于方式（2）是一种更难学习的监督方式，网络需要自行将空间位置转换为坐标。

方式（2）中网络的任务很直观，把和目标相似的位置输出高激活值就OK，这其实可以理解成在做滤波，也就是卷积干的事情

# 总结论文改进之处：

1. 采用自顶向下的算法构建：

   先用现成的检测器获取单个人的bounding box，然后从bounding box中单独提取每个人的pose

2. 使用SimCC预测关键点：

   - 将水平和垂直轴划分为等宽编号的 bin，并将连续坐标离散为积分 bin 标签
   - 使用7*7的卷积层（实验结论）
   - 删去了计算消耗大的上采样层
   - 使用CSPNext-m作为backbone

3. 训练策略：

   - 采用UDP（The Devil is in the Details: Delving into Unbiased Data Processing for Human Pose Estimation）对backbone进行预训练
   - 优化方法：指数移动平均(ema）和平面余弦退火策略
   - strong-then-weak的两阶段训练增强：（强）cutout有助于防止模型过度拟合**图像纹理**，并鼓励它学习姿势结构信息。（弱）微调使其更符合真实的图片分布。

4. 推理管线：

   - 跳跃帧检测机制：其中每个 k 帧执行人体检测，在间隔帧中，边界框是从*最后一个姿态估计结果*生成的
   - 后处理阶段基于oks的姿态nms和oneEuro[9]滤波器

5. 自注意力机制（GAU:Gated Attention Unit）:

   自注意产生公式：

   ![image-20240807203443959](C:\Users\denglitao\AppData\Roaming\Typora\typora-user-images\image-20240807203443959.png)

overall architecture:

![image-20240807203522006](C:\Users\denglitao\AppData\Roaming\Typora\typora-user-images\image-20240807203522006.png)
